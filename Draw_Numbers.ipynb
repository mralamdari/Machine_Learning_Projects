{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AOIhK7VjyUwQ",
        "R9UDAmpByTIe"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOZcUXXniGMh4U7VXnwuJJZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/Machine_Learning_Projects/blob/main/Draw_Numbers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1"
      ],
      "metadata": {
        "id": "AOIhK7VjyUwQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2Gu2slItPV0"
      },
      "outputs": [],
      "source": [
        "import pygame, sys\n",
        "import os, numpy as np\n",
        "from tkinter import *\n",
        "from tkinter import messagebox\n",
        "import tensorflow as tf\n",
        "\n",
        "class pixel(object):\n",
        "    def __init__(self, x, y, width, height):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.color = (255, 255, 255)\n",
        "        self.neighbors = []\n",
        "\n",
        "    def draw(self, surface):\n",
        "        pygame.draw.rect(surface, self.color, (self.x, self.y, self.width + self.x, self.y + height))\n",
        "\n",
        "    def getNeighbors(self, g):\n",
        "        j = self.x // 20\n",
        "        i = self.y // 20\n",
        "        rows = cols = 28\n",
        "\n",
        "        # Horizontal and vertical neighbors\n",
        "        if i < cols - 1:  # Right\n",
        "            self.neighbors.append(g.pixels[i + 1][j])\n",
        "        if i > 0:  # Left\n",
        "            self.neighbors.append(g.pixels[i - 1][j])\n",
        "        if j < rows - 1:  # Up\n",
        "            self.neighbors.append(g.pixels[i][j + 1])\n",
        "        if j > 0:  # Down\n",
        "            self.neighbors.append(g.pixels[i][j - 1])\n",
        "\n",
        "        # Diagonal neighbors\n",
        "        if j > 0 and i > 0:  # Top Left\n",
        "            self.neighbors.append(g.pixels[i - 1][j - 1])\n",
        "\n",
        "        if j + 1 < rows and i > -1 and i - 1 > 0:  # Bottom Left\n",
        "            self.neighbors.append(g.pixels[i - 1][j + 1])\n",
        "\n",
        "        if j - 1 < rows and i < cols - 1 and j - 1 > 0:  # Top Right\n",
        "            self.neighbors.append(g.pixels[i + 1][j - 1])\n",
        "\n",
        "        if j < rows - 1 and i < cols - 1:  # Bottom Right\n",
        "            self.neighbors.append(g.pixels[i + 1][j + 1])\n",
        "\n",
        "\n",
        "class grid(object):\n",
        "    pixels = []\n",
        "\n",
        "    def __init__(self, row, col, width, height):\n",
        "        self.rows = row\n",
        "        self.cols = col\n",
        "        self.width = width\n",
        "        self.len = row * col\n",
        "        self.height = height\n",
        "        self.generatePixles()\n",
        "        pass\n",
        "\n",
        "    def draw(self, surface):\n",
        "        for row in self.pixels:\n",
        "            for col in row:\n",
        "                col.draw(surface)\n",
        "\n",
        "    def generatePixles(self):\n",
        "        x_gap = self.width // self.cols\n",
        "        y_gap = self.height // self.rows\n",
        "        self.pixels = []\n",
        "        for r in range(self.rows):\n",
        "            self.pixels.append([])\n",
        "            for c in range(self.cols):\n",
        "                self.pixels[r].append(pixel(x_gap * c, y_gap * r, x_gap, y_gap))\n",
        "\n",
        "        for r in range(self.rows):\n",
        "            for c in range(self.cols):\n",
        "                self.pixels[r][c].getNeighbors(self)\n",
        "\n",
        "    def clicked(self, pos):\n",
        "        try:\n",
        "            t = pos[0]\n",
        "            w = pos[1]\n",
        "            g1 = int(t) // self.pixels[0][0].width\n",
        "            g2 = int(w) // self.pixels[0][0].height\n",
        "            return self.pixels[g2][g1]\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "\n",
        "    def convert_binary(self):\n",
        "        li = self.pixels\n",
        "        mat = np.zeros(shape=(1, 28, 28))\n",
        "        for i in range(len(li)):\n",
        "            for j in range(len(li[i])):\n",
        "                if li[i][j].color != (255, 255, 255):\n",
        "                    mat[0][i][j] = 1\n",
        "        return mat\n",
        "\n",
        "\n",
        "def guess(li):\n",
        "    num_list = [\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]\n",
        "    model = tf.keras.models.load_model(\"Final_Model.h5\")\n",
        "    pred = model.predict(li)\n",
        "    t = tf.argmax(pred[0])\n",
        "    print(f\"As my prediction, The number you entered is: {num_list[t].capitalize()}\")\n",
        "    window = Tk()\n",
        "    window.withdraw()\n",
        "    messagebox.showinfo(\"Prediction\", f\"As my prediction, The number you entered is: {num_list[t].capitalize()} ===> {t}\")\n",
        "    window.destroy()\n",
        "\n",
        "def main():\n",
        "    run = True\n",
        "\n",
        "    while run:\n",
        "        for event in pygame.event.get():\n",
        "            if event.type == pygame.QUIT:\n",
        "                run = False\n",
        "            if event.type == pygame.KEYDOWN:\n",
        "                li = g.convert_binary()\n",
        "                guess(li)\n",
        "                g.generatePixles()\n",
        "            if pygame.mouse.get_pressed()[0]:\n",
        "                pos = pygame.mouse.get_pos()\n",
        "                clicked = g.clicked(pos)\n",
        "                clicked.color=(0, 0, 255)\n",
        "                for o in clicked.neighbors:\n",
        "                    o.color=(0, 0, 255)\n",
        "            if pygame.mouse.get_pressed()[2]:\n",
        "                try:\n",
        "                    pos = pygame.mouse.get_pos()\n",
        "                    cliked = g.cliked(pos)\n",
        "                    clicked.color = (255, 255, 255)\n",
        "                except:\n",
        "                    pass\n",
        "        g.draw(win)\n",
        "        pygame.display.update()\n",
        "\n",
        "pygame.init()\n",
        "width = height = 560\n",
        "win = pygame.display.set_mode((width, height))\n",
        "pygame.display.set_caption(\"E.F.A Number Guesser\")\n",
        "g = grid(28, 28, width, height)\n",
        "main()\n",
        "pygame.quit()\n",
        "\n",
        "quit()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn import ensemble\n",
        "from sklearn import model_selection\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mnist = datasets.fetch_openml('mnist_784', version=1)\n",
        "\n",
        "mnist.feature_names\n",
        "\n",
        "x, y = mnist.data, mnist.target\n",
        "\n",
        "X = np.nan_to_num(x, copy=True)\n",
        "X.shape\n",
        "\n",
        "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y, random_state=77, test_size=0.2)\n",
        "\n",
        "def standardization(x):\n",
        "    return (x - np.mean(x, axis=0)) / np.std(x, axis=0)\n",
        "\n",
        "x_train_std = standardization(x_train)\n",
        "x_test_std  = standardization(x_test)\n",
        "\n",
        "x_train = np.nan_to_num(x_train_std)\n",
        "x_test  = np.nan_to_num(x_test_std)\n",
        "\n",
        "clf = sklearn.ensemble.RandomForestClassifier()\n",
        "\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "pred = clf.predict(x_test)\n",
        "\n",
        "score= sklearn.metrics.accuracy_score(y_test, pred)\n",
        "\n",
        "print(f'The Validation Score: %{100*score:.2f}')\n",
        "\n",
        "# rand_ind = np.random.randint(0, len(x_test), 16)\n",
        "\n",
        "fig, axs = plt.subplots(4, 4, figsize=(12, 12))\n",
        "# plt.gray()\n",
        "\n",
        "for r, ax in zip(rand_ind, axs.flat):\n",
        "\n",
        "    ax.set_title(y_test.values[r])\n",
        "    ax.matshow(x_test[r].reshape(28, 28))\n",
        "    ax.axis('off')\n",
        "\n",
        "fig.show()\n",
        "\n",
        "\"\"\"# Deep Learning Approch\"\"\"\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "input_size=784     # Each Image has 784 features(pixels) 784 = 28*28\n",
        "out_size=10        # 10 Numbers\n",
        "epochs=10          # Iterations\n",
        "batch_size=100\n",
        "learning_rate=0.001\n",
        "\n",
        "mean_gray = 0.1307\n",
        "std_grey  = 0.3081\n",
        "\n",
        "transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
        "                                             torchvision.transforms.Normalize((mean_gray, ), (std_grey, ))])\n",
        "\n",
        "train_ds = torchvision.datasets.MNIST(root='/data',\n",
        "                                      train = True,\n",
        "                                      transform = torchvision.transforms.ToTensor(),\n",
        "                                      download=True)\n",
        "\n",
        "test_ds = torchvision.datasets.MNIST(root='/data',\n",
        "                                      train=False,\n",
        "                                      transform = torchvision.transforms.ToTensor(),\n",
        "                                      download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_ds,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_ds,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
        "    self.batchnorm1 = torch.nn.BatchNorm2d(8)\n",
        "    self.relu = torch.nn.ReLU()\n",
        "    self.maxpool = torch.nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv2 = torch.nn.Conv2d(in_channels=8, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
        "    self.batchnorm2 = torch.nn.BatchNorm2d(32)\n",
        "    self.fc1 = torch.nn.Linear(32*7*7, 600)\n",
        "    self.dropout = torch.nn.Dropout(p=0.5)\n",
        "    self.fc2 = torch.nn.Linear(600, 100)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv1(x)\n",
        "    out = self.batchnorm1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.maxpool(out)\n",
        "    out = self.conv2(out)\n",
        "    out = self.batchnorm2(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.maxpool(out)\n",
        "\n",
        "    out = out.view(-1, 1568)\n",
        "\n",
        "    out = self.fc1(out)\n",
        "    out = self.dropout(out)\n",
        "    out = self.fc2(out)\n",
        "    return out\n",
        "\n",
        "model = Net()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(device)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "num_epochs=20\n",
        "train_loss = []\n",
        "train_accuracy = []\n",
        "test_loss = []\n",
        "test_accuracy = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  correct = 0\n",
        "  iterations = 0\n",
        "  iter_loss = 0.0\n",
        "\n",
        "  # Training Part\n",
        "  model.train()\n",
        "  for i, (inputs, labels) in enumerate(train_loader):\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "    iter_loss += loss.item()\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    _, pred = torch.max(outputs, 1)\n",
        "    correct += (pred == labels).sum().item()\n",
        "    iterations += 1\n",
        "\n",
        "  train_loss.append(iter_loss/iterations)\n",
        "  train_accuracy.append(100 * correct/ len(train_ds))\n",
        "\n",
        "  # Validation Part\n",
        "  t_loss = 0.0\n",
        "  correct = 0\n",
        "  iterations = 0\n",
        "  model.eval()\n",
        "  for i, (inputs, labels) in enumerate(test_loader):\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "    t_loss += loss.item()\n",
        "    _, pred = torch.max(outputs, 1) #(100, 10)  ==> 10 is in index 1\n",
        "    correct += (pred == labels).sum().item()\n",
        "    iterations += 1\n",
        "\n",
        "  test_loss.append(t_loss/iterations)\n",
        "  test_accuracy.append(100*correct/len(test_ds))\n",
        "\n",
        "\n",
        "  print(f'epoch: {epoch+1}, Training Loss: {train_loss[-1]:.3f}, Training Accuracy: %{train_accuracy[-1]:.3f}, Test Loss: {test_loss[-1]:.3f}, Test Accuracy:% {test_accuracy[-1]:.3f}')\n",
        "\n",
        "def plot_curves(train_arr, test_arr, title=\"Accuracy\"):\n",
        "  epochs = range(1, len(test_arr)+1)\n",
        "  plt.figure()\n",
        "  plt.title(title)\n",
        "  plt.plot(epochs, train_arr, label=\"Training\")\n",
        "  plt.plot(epochs, test_arr, label=\"Testing\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "plot_curves(train_loss, test_loss, 'Loss')\n",
        "\n",
        "plot_curves(train_accuracy, test_accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "b43TVmwbtWK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2"
      ],
      "metadata": {
        "id": "R9UDAmpByTIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "cd7NNdU_wYTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(name):\n",
        "  return \"Hello \" + name + \"!\"\n",
        "\n",
        "greet(\"World\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "A5iWFvp8wJxj",
        "outputId": "d2cc98c9-4cda-4c08-8a37-3703500bddc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello World!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install typing-extensions --upgrade\n",
        "# !pip uninstall typing-extensions\n",
        "# !pip install -U typing-extensions"
      ],
      "metadata": {
        "id": "XdBPdvC0zZ39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gradio as gr\n",
        "\n",
        "def sepia(input_img):\n",
        "    sepia_filter = np.array([\n",
        "        [0.393, 0.769, 0.189],\n",
        "        [0.349, 0.686, 0.168],\n",
        "        [0.272, 0.534, 0.131]\n",
        "    ])\n",
        "    sepia_img = input_img.dot(sepia_filter.T)\n",
        "    sepia_img /= sepia_img.max()\n",
        "    return sepia_img\n",
        "\n",
        "demo = gr.Interface(sepia, gr.Image(type=\"pil\"), \"image\")\n",
        "demo.launch(share=False)"
      ],
      "metadata": {
        "id": "KLLCfr21wab-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def greet(name):\n",
        "    return \"Hello \" + name + \"!\"\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=greet,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Name Here...\"),\n",
        "    outputs=\"text\",\n",
        ")\n",
        "# demo.launch(share=False)"
      ],
      "metadata": {
        "id": "yJfQhmV8whVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def greet(name, is_morning, temperature):\n",
        "    salutation = \"Good morning\" if is_morning else \"Good evening\"\n",
        "    greeting = f\"{salutation} {name}. It is {temperature} degrees today\"\n",
        "    celsius = (temperature - 32) * 5 / 9\n",
        "    return greeting, round(celsius, 2)\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=greet,\n",
        "    inputs=[\"text\", \"checkbox\", gr.Slider(0, 100)],\n",
        "    outputs=[\"text\", \"number\"],\n",
        ")\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "IN5o4gH0wfs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gradio as gr\n",
        "\n",
        "def sepia(input_img):\n",
        "    sepia_filter = np.array([\n",
        "        [0.393, 0.769, 0.189],\n",
        "        [0.349, 0.686, 0.168],\n",
        "        [0.272, 0.534, 0.131]\n",
        "    ])\n",
        "    sepia_img = input_img.dot(sepia_filter.T)\n",
        "    sepia_img /= sepia_img.max()\n",
        "    return sepia_img\n",
        "\n",
        "demo = gr.Interface(sepia, gr.Image(type=\"filepath\", shape=...), \"image\")\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "t0LgIokhwfqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Image(type=\"filepath\", shape=...)\n",
        "img = gr.Image(shape=(100, 100), type=\"pil\")\n",
        "img = gr.Image(invert_colors=True, type=\"numpy\")\n",
        "demo = gr.Interface(..., theme=gr.themes.Monochrome())\n"
      ],
      "metadata": {
        "id": "QkKDEMxXwqyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import time\n",
        "\n",
        "def slowly_reverse(word, progress=gr.Progress()):\n",
        "    progress(0, desc=\"Starting\")\n",
        "    time.sleep(1)\n",
        "    progress(0.05)\n",
        "    new_string = \"\"\n",
        "    for letter in progress.tqdm(word, desc=\"Reversing\"):\n",
        "        time.sleep(0.25)\n",
        "        new_string = letter + new_string\n",
        "    return new_string\n",
        "\n",
        "demo = gr.Interface(slowly_reverse, gr.Text(), gr.Text())\n",
        "\n",
        "demo.launch(share=False)\n"
      ],
      "metadata": {
        "id": "e4gn3nO0x8d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# define core fn, which returns a generator {steps} times before returning the image\n",
        "def fake_diffusion(steps):\n",
        "    for _ in range(steps):\n",
        "        time.sleep(1)\n",
        "        image = np.random.random((600, 600, 3))\n",
        "        yield image\n",
        "    image = np.ones((1000,1000,3), np.uint8)\n",
        "    image[:] = [255, 124, 0]\n",
        "    yield image\n",
        "\n",
        "\n",
        "demo = gr.Interface(fake_diffusion, inputs=gr.Slider(1, 10, 3), outputs=\"image\")\n",
        "\n",
        "# define queue - required for generators\n",
        "demo.queue()\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "OXV4tzRfx4KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import gradio as gr\n",
        "\n",
        "def random_response(message, history):\n",
        "    return random.choice([\"Yes\", \"No\"])\n",
        "\n",
        "demo = gr.ChatInterface(random_response)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "Z-mPYrJvw8pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "def greet(name):\n",
        "    return \"Hello \" + name + \"!\"\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    name = gr.Textbox(label=\"Name\")\n",
        "    output = gr.Textbox(label=\"Output Box\")\n",
        "    greet_btn = gr.Button(\"Greet\")\n",
        "    greet_btn.click(fn=greet, inputs=name, outputs=output, api_name=\"greet\")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "G6Uudl73w8mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "def flip_text(x):\n",
        "    return x[::-1]\n",
        "\n",
        "\n",
        "def flip_image(x):\n",
        "    return np.fliplr(x)\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"Flip text or image files using this demo.\")\n",
        "    with gr.Tab(\"Flip Text\"):\n",
        "        text_input = gr.Textbox()\n",
        "        text_output = gr.Textbox()\n",
        "        text_button = gr.Button(\"Flip\")\n",
        "    with gr.Tab(\"Flip Image\"):\n",
        "        with gr.Row():\n",
        "            image_input = gr.Image()\n",
        "            image_output = gr.Image()\n",
        "        image_button = gr.Button(\"Flip\")\n",
        "\n",
        "    with gr.Accordion(\"Open for More!\"):\n",
        "        gr.Markdown(\"Look at me...\")\n",
        "\n",
        "    text_button.click(flip_text, inputs=text_input, outputs=text_output)\n",
        "    image_button.click(flip_image, inputs=image_input, outputs=image_output)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "AAQ9tPSPxHmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "#from foo import BAR\n",
        "#\n",
        "def calculator(num1, operation, num2):\n",
        "    if operation == \"add\":\n",
        "        return num1 + num2\n",
        "    elif operation == \"subtract\":\n",
        "        return num1 - num2\n",
        "    elif operation == \"multiply\":\n",
        "        return num1 * num2\n",
        "    elif operation == \"divide\":\n",
        "        if num2 == 0:\n",
        "            raise gr.Error(\"Cannot divide by zero!\")\n",
        "        return num1 / num2\n",
        "\n",
        "demo = gr.Interface(\n",
        "    calculator,\n",
        "    [\n",
        "        \"number\",\n",
        "        gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]),\n",
        "        \"number\"\n",
        "    ],\n",
        "    \"number\",\n",
        "    examples=[\n",
        "        [45, \"add\", 3],\n",
        "        [3.14, \"divide\", 2],\n",
        "        [144, \"multiply\", 2.5],\n",
        "        [0, \"subtract\", 1.2],\n",
        "    ],\n",
        "    title=\"Toy Calculator\",\n",
        "    description=\"Here's a sample toy calculator. Allows you to calculate things like $2+2=4$\",\n",
        ")\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "SODeWoCmxXdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3"
      ],
      "metadata": {
        "id": "1tZTPVYOKcRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "v-Q-FEE3fs5N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = np.expand_dims(x_train, axis=-1) / 255\n",
        "x_test  = np.expand_dims(x_test , axis=-1) / 255\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y=y_train, num_classes=10)\n",
        "y_test  = tf.keras.utils.to_categorical(y=y_test , num_classes=10)\n",
        "\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG36zqNEKc7U",
        "outputId": "49877981-cce1-4c2f-8909-70054ae459ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1), (60000, 10), (10000, 28, 28, 1), (10000, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = plt.imshow(x_train[8][:,:,0])"
      ],
      "metadata": {
        "id": "vI4jtyriarG_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "c7c2ae8f-b9b7-43e3-9e5b-03eaad1ab0a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(37,))(x)\n",
        "x = tf.keras.layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=(28, 28, 1))(x)\n",
        "x = tf.keras.layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
        "x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "\n",
        "\n",
        "x = keras.layers.Dense(32, activation=\"relu\")(inputs)\n",
        "outputs = keras.layers.Dense(5, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n"
      ],
      "metadata": {
        "id": "dEtsBiombLhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv2d()\n",
        "\n",
        "        self.dense1 = keras.layers.Dense(32, activation=\"relu\")\n",
        "\n",
        "        self.dense2 = keras.layers.Dense(5, activation=\"softmax\")\n",
        "        self.dropout = keras.layers.Dropout(0.5)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "\n",
        "        tf.keras.layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "        tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
        "        tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.dropout(x, training=training)\n",
        "        return self.dense2(x)\n",
        "\n",
        "model = MyModel()"
      ],
      "metadata": {
        "id": "5oQLsuKdbv3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vfy0M0XKk58",
        "outputId": "6c690d3e-1431-4a07-ee6b-15d323f657ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 16)        160       \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 16)        2320      \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 28, 28, 16)        64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 28, 28, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 28, 28, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 7, 7, 64)          256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " global_average_pooling2d_1  (None, 64)                0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 72890 (284.73 KB)\n",
            "Trainable params: 72666 (283.85 KB)\n",
            "Non-trainable params: 224 (896.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "             loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "             metrics=[tf.keras.metrics.MeanSquaredError(), tf.keras.metrics.AUC(), tf.keras.metrics.CategoricalAccuracy()])\n",
        "\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=2),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.4f}-{categorical_accuracy:0.4f}.keras'),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs')]\n",
        "\n",
        "\n",
        "history=model.fit(x=x_train,\n",
        "                  y=y_train,\n",
        "                  epochs=20,\n",
        "                  verbose=1,\n",
        "                  batch_size=32,\n",
        "                  callbacks=my_callbacks,\n",
        "                  validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s98wdR-ULOE3",
        "outputId": "52cb0fdf-aaf5-45ff-a243-6811864f2c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 297s 157ms/step - loss: 0.1724 - mean_squared_error: 0.0073 - auc_2: 0.9984 - categorical_accuracy: 0.9607 - val_loss: 0.1200 - val_mean_squared_error: 0.0056 - val_auc_2: 0.9986 - val_categorical_accuracy: 0.9615\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 295s 157ms/step - loss: 0.0624 - mean_squared_error: 0.0028 - auc_2: 0.9994 - categorical_accuracy: 0.9823 - val_loss: 0.2964 - val_mean_squared_error: 0.0144 - val_auc_2: 0.9929 - val_categorical_accuracy: 0.9054\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 307s 164ms/step - loss: 0.0462 - mean_squared_error: 0.0022 - auc_2: 0.9996 - categorical_accuracy: 0.9864 - val_loss: 0.1167 - val_mean_squared_error: 0.0054 - val_auc_2: 0.9982 - val_categorical_accuracy: 0.9648\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 319s 170ms/step - loss: 0.0387 - mean_squared_error: 0.0018 - auc_2: 0.9996 - categorical_accuracy: 0.9881 - val_loss: 0.0378 - val_mean_squared_error: 0.0018 - val_auc_2: 0.9998 - val_categorical_accuracy: 0.9878\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 336s 179ms/step - loss: 0.0315 - mean_squared_error: 0.0015 - auc_2: 0.9998 - categorical_accuracy: 0.9904 - val_loss: 0.0576 - val_mean_squared_error: 0.0027 - val_auc_2: 0.9992 - val_categorical_accuracy: 0.9832\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 300s 160ms/step - loss: 0.0288 - mean_squared_error: 0.0014 - auc_2: 0.9997 - categorical_accuracy: 0.9912 - val_loss: 0.0660 - val_mean_squared_error: 0.0032 - val_auc_2: 0.9992 - val_categorical_accuracy: 0.9784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.Model.save(model, 'weights.h5')\n",
        "model.save('my_model.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TC_3p0MWgYK",
        "outputId": "860dd512-ed51-479a-aac4-e31db34f21f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = tf.keras.models.load_model('/content/weights.h5')\n",
        "y_pred = new_model.predict(x_train)\n",
        "# y_pred = model.predict(x_train)\n",
        "\n",
        "pred   = np.argmax(y_pred, axis=1)\n",
        "Y = np.argmax(y_train, axis=1)\n",
        "confusion_mtx = metrics.confusion_matrix(Y, pred)\n",
        "\n",
        "labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "print(f'Accuracy: {np.sum(Y==pred)/len(pred)}')\n",
        "print(confusion_mtx)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(confusion_mtx)\n",
        "plt.title('Confusion matrix')\n",
        "fig.colorbar(cax)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XvoM670gOzUp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "outputId": "9059a58d-2619-4c92-9856-9dd40b64e27e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 49s 26ms/step\n",
            "Accuracy: 0.83345\n",
            "[[5867    5    0    0    5    0   43    0    3    0]\n",
            " [   3 6728    0    0   11    0    0    0    0    0]\n",
            " [ 124  492 4740   27  126   34  388    3   24    0]\n",
            " [  14   46   14 5987    7   43    2    1   17    0]\n",
            " [   7   17    0    0 5795    0   20    1    2    0]\n",
            " [  20  194    0    5   10 4925  260    1    6    0]\n",
            " [  13   11    0    0    3    0 5891    0    0    0]\n",
            " [  75 3444    5   29  337   16    3 2354    2    0]\n",
            " [  95   16    0   13   53   12  302    0 5360    0]\n",
            " [ 468   80    4    9 2751   19  190    5   63 2360]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = np.random.randint(0, len(x_test))\n",
        "test_img = x_test[N].squeeze(-1)\n",
        "test_img = np.array(test_img).reshape(1, test_img.shape[0], test_img.shape[1], 1)\n",
        "prediction = model.predict(test_img)\n",
        "pred   = np.argmax(prediction, axis=1)[0]\n",
        "print(f'True Label: {np.argmax(y_test[N])}, Prediction: {pred}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08qze7i9e2m-",
        "outputId": "233108bb-f3db-4b97-8464-ac69f052b4e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 187ms/step\n",
            "True Label: 1, Prediction: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.Model.save(model, 'weights.h5')\n",
        "model.save('my_model.keras')"
      ],
      "metadata": {
        "id": "ZzYA8hPl6wix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d6fbbf2-2efe-408d-d003-ba9cee400af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "NhGZ_aFO917c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.load('my_model.keras')\n",
        "new_model = tf.keras.models.load_model('/content/model.05-0.12.keras')\n",
        "# new_model = tf.keras.models.load_model('weights.h5')"
      ],
      "metadata": {
        "id": "7aWOFIvm-vM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = tf.keras.models.load_model('/content/my_model.keras')\n",
        "# y_pred = new_model.predict(x_train)\n",
        "N = np.random.randint(0, len(x_test))\n",
        "test_img = x_test[N].squeeze(-1)\n",
        "test_img = np.array(test_img).reshape(1, test_img.shape[0], test_img.shape[1], 1)\n",
        "prediction = new_model.predict(test_img)\n",
        "pred   = np.argmax(prediction, axis=1)[0]\n",
        "print(f'True Label: {np.argmax(y_test[N])}, Prediction: {pred}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6efsKqj7-3B_",
        "outputId": "9907cab5-9fa5-4d49-e2e5-3032c6bd2fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 487 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ab565ea5e10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 206ms/step\n",
            "True Label: 4, Prediction: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.path.getsize('weights.h5'), os.path.getsize('my_model.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_-kgrc6_WKe",
        "outputId": "d2913ba4-0ada-40d4-9a3f-52f8873a63d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(961808, 947947)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4"
      ],
      "metadata": {
        "id": "mMB0XG9fjbQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "mTUCIYxXmdha"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "# x_train.shape\n",
        "\n",
        "# x_train = x_train.astype(\"float32\") / 255.0\n",
        "# x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# # Add a channel dimension to the images\n",
        "# x_train = x_train[..., tf.newaxis]\n",
        "# x_test = x_test[..., tf.newaxis]\n",
        "\n",
        "# x_train = tf.image.resize(x_train, [32, 32])\n",
        "# x_test = tf.image.resize(x_test, [32, 32])\n",
        "\n",
        "# x_train.shape"
      ],
      "metadata": {
        "id": "eQbX1TYenZET"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = np.expand_dims(x_train, axis=-1) / 255\n",
        "x_test  = np.expand_dims(x_test , axis=-1) / 255\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y=y_train, num_classes=10)\n",
        "y_test  = tf.keras.utils.to_categorical(y=y_test , num_classes=10)\n",
        "\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juVE_B56jc5A",
        "outputId": "fda88e8f-a073-49a7-fe98-f29c719275fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1), (60000, 10), (10000, 28, 28, 1), (10000, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = plt.imshow(x_train[8][:,:,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "zaVzNOj_jfR1",
        "outputId": "9ce1f31a-05b6-427d-a748-d44e13b18a3c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kyeq2Uwlj1J-",
        "outputId": "a0490bc1-8213-4146-8d17-16b79b45ef67"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 16)        160       \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 28, 28, 16)        2320      \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 28, 28, 16)        64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 28, 28, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 7, 7, 64)          256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " global_average_pooling2d_1  (None, 64)                0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 72890 (284.73 KB)\n",
            "Trainable params: 72666 (283.85 KB)\n",
            "Non-trainable params: 224 (896.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "             loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              # loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "             metrics=[tf.keras.metrics.MeanSquaredError(), tf.keras.metrics.AUC(), tf.keras.metrics.CategoricalAccuracy()])\n",
        "\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=5),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.4f}-{categorical_accuracy:0.4f}.h5'),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs')]\n",
        "\n",
        "\n",
        "history=model.fit(x=x_train,\n",
        "                  y=y_train,\n",
        "                  epochs=50,\n",
        "                  verbose=1,\n",
        "                  batch_size=32,\n",
        "                  callbacks=my_callbacks,\n",
        "                  validation_data=(x_test, y_test))\n",
        "\n",
        "\n",
        "model.evaluate(x_test, y_test)\n",
        "model.save(\"my_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_Y1xnD2kStU",
        "outputId": "0f5e3e89-96e7-4530-9686-0de719761297"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 18s 8ms/step - loss: 0.0342 - mean_squared_error: 0.0016 - auc_1: 0.9997 - categorical_accuracy: 0.9894 - val_loss: 0.0933 - val_mean_squared_error: 0.0046 - val_auc_1: 0.9983 - val_categorical_accuracy: 0.9702\n",
            "Epoch 2/50\n",
            "  19/1875 [..............................] - ETA: 11s - loss: 0.0452 - mean_squared_error: 0.0021 - auc_1: 0.9991 - categorical_accuracy: 0.9836"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0278 - mean_squared_error: 0.0013 - auc_1: 0.9998 - categorical_accuracy: 0.9915 - val_loss: 0.0475 - val_mean_squared_error: 0.0023 - val_auc_1: 0.9994 - val_categorical_accuracy: 0.9854\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0239 - mean_squared_error: 0.0011 - auc_1: 0.9998 - categorical_accuracy: 0.9926 - val_loss: 0.0513 - val_mean_squared_error: 0.0024 - val_auc_1: 0.9991 - val_categorical_accuracy: 0.9837\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0239 - mean_squared_error: 0.0012 - auc_1: 0.9998 - categorical_accuracy: 0.9926 - val_loss: 0.0628 - val_mean_squared_error: 0.0030 - val_auc_1: 0.9987 - val_categorical_accuracy: 0.9800\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0185 - mean_squared_error: 9.0418e-04 - auc_1: 0.9999 - categorical_accuracy: 0.9942 - val_loss: 0.0712 - val_mean_squared_error: 0.0033 - val_auc_1: 0.9984 - val_categorical_accuracy: 0.9790\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0168 - mean_squared_error: 8.1764e-04 - auc_1: 0.9999 - categorical_accuracy: 0.9947 - val_loss: 0.0554 - val_mean_squared_error: 0.0027 - val_auc_1: 0.9991 - val_categorical_accuracy: 0.9824\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0147 - mean_squared_error: 7.2710e-04 - auc_1: 0.9999 - categorical_accuracy: 0.9953 - val_loss: 0.0256 - val_mean_squared_error: 0.0013 - val_auc_1: 0.9998 - val_categorical_accuracy: 0.9917\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0138 - mean_squared_error: 6.6068e-04 - auc_1: 0.9999 - categorical_accuracy: 0.9958 - val_loss: 0.0629 - val_mean_squared_error: 0.0028 - val_auc_1: 0.9985 - val_categorical_accuracy: 0.9816\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0127 - mean_squared_error: 6.2981e-04 - auc_1: 0.9999 - categorical_accuracy: 0.9960 - val_loss: 0.0331 - val_mean_squared_error: 0.0016 - val_auc_1: 0.9994 - val_categorical_accuracy: 0.9895\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0112 - mean_squared_error: 5.5706e-04 - auc_1: 0.9999 - categorical_accuracy: 0.9964 - val_loss: 0.0330 - val_mean_squared_error: 0.0015 - val_auc_1: 0.9994 - val_categorical_accuracy: 0.9901\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0101 - mean_squared_error: 5.0282e-04 - auc_1: 0.9999 - categorical_accuracy: 0.9968 - val_loss: 0.0453 - val_mean_squared_error: 0.0020 - val_auc_1: 0.9991 - val_categorical_accuracy: 0.9875\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0093 - mean_squared_error: 4.7934e-04 - auc_1: 1.0000 - categorical_accuracy: 0.9969 - val_loss: 0.0433 - val_mean_squared_error: 0.0020 - val_auc_1: 0.9989 - val_categorical_accuracy: 0.9869\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0433 - mean_squared_error: 0.0020 - auc_1: 0.9989 - categorical_accuracy: 0.9869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "g7r_xCFNo8lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# import gradio as gr\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "# from efficientnet.tfkeras import EfficientNetB0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "             loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              # loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "             metrics=[tf.keras.metrics.MeanSquaredError(), tf.keras.metrics.AUC(), tf.keras.metrics.CategoricalAccuracy()])\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "#     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#     metrics=[\"accuracy\"],\n",
        "# )\n",
        "\n",
        "model = tf.keras.models.load_model('my_model.h5')\n",
        "\n",
        "def classify_image(image):\n",
        "    image_gray = tf.image.rgb_to_grayscale(image)\n",
        "    image_tensor = tf.convert_to_tensor(image_gray)\n",
        "    image_tensor = tf.cast(image_tensor, tf.float32)\n",
        "    image_tensor = tf.expand_dims(image_tensor, 0)\n",
        "    image_tensor = image_tensor / 255.0\n",
        "    prediction = model.predict(image_tensor)\n",
        "    prediction_label = str(prediction.argmax())\n",
        "\n",
        "    return prediction_label\n",
        "\n",
        "title = \"MNIST Model 98%acc\"\n",
        "description = \"Model trained on MNIST dataset using efficientnet to classify MNIST images with 98% accuracy\"\n",
        "article = \"for source code you can visit [my github](https://github.com/Bijan-K/Tensorflow-MNIST-98Acc.git) (gradio + training code).\"\n",
        "\n",
        "example_list = [[\"examples/\" + example] for example in os.listdir(\"examples\")]\n",
        "\n",
        "# interface = gr.Interface(fn=classify_image,\n",
        "#                           inputs=gr.Image(type=\"pil\"),\n",
        "#                           outputs=gr.Label(num_top_classes=3, label=\"Predictions\"),\n",
        "#                           examples=example_list,\n",
        "#                           title=title,\n",
        "#                           description=description,\n",
        "#                           article=article)\n",
        "\n",
        "\n",
        "# interface.launch()"
      ],
      "metadata": {
        "id": "__gYiDP0kSXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fDu4ZW4jf7he"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}