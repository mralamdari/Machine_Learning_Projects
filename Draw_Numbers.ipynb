{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AOIhK7VjyUwQ",
        "R9UDAmpByTIe",
        "1tZTPVYOKcRD"
      ],
      "authorship_tag": "ABX9TyPxfOwDqQ4BXOAAm4nLZr4c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/Machine_Learning_Projects/blob/main/Draw_Numbers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "mTUCIYxXmdha"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = np.expand_dims(x_train, axis=-1) / 255\n",
        "x_test  = np.expand_dims(x_test , axis=-1) / 255\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y=y_train, num_classes=10)\n",
        "y_test  = tf.keras.utils.to_categorical(y=y_test , num_classes=10)\n",
        "\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juVE_B56jc5A",
        "outputId": "d3e8dd73-0d8c-4ca8-8029-5b390db30437"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1), (60000, 10), (10000, 28, 28, 1), (10000, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = plt.imshow(x_train[8][:,:,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "zaVzNOj_jfR1",
        "outputId": "bca9becd-bea4-4fa8-d375-bd65b7b0c2a3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
        "    # tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
        "    # tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kyeq2Uwlj1J-",
        "outputId": "b29e08c3-7d4e-401c-adbc-b35de31d6e49"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 16)        160       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 16)        2320      \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 28, 28, 16)        64        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 28, 28, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 32)                0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16890 (65.98 KB)\n",
            "Trainable params: 16794 (65.60 KB)\n",
            "Non-trainable params: 96 (384.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "             loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              # loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "            #  metrics=[tf.keras.metrics.MeanSquaredError(), tf.keras.metrics.AUC(), tf.keras.metrics.CategoricalAccuracy()]\n",
        "              metrics=['accuracy']\n",
        "              )\n",
        "\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=5),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.4f}-{categorical_accuracy:0.4f}.h5'),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs')]\n",
        "\n",
        "\n",
        "history=model.fit(x=x_train,\n",
        "                  y=y_train,\n",
        "                  epochs=50,\n",
        "                  verbose=1,\n",
        "                  batch_size=32,\n",
        "                  callbacks=my_callbacks,\n",
        "                  validation_data=(x_test, y_test))\n",
        "\n",
        "\n",
        "model.evaluate(x_test, y_test)\n",
        "model.save(\"my_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_Y1xnD2kStU",
        "outputId": "8d08902c-0590-410b-cc2d-f2eca1a3f4c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "  64/1875 [>.............................] - ETA: 2:51 - loss: 1.9669 - accuracy: 0.3779"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "g7r_xCFNo8lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "             loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              # loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "             metrics=[tf.keras.metrics.MeanSquaredError(), tf.keras.metrics.AUC(), tf.keras.metrics.CategoricalAccuracy()])\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "#     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#     metrics=[\"accuracy\"],\n",
        "# )\n",
        "\n",
        "model = tf.keras.models.load_model('my_model.h5')\n",
        "\n",
        "def classify_image(image):\n",
        "    if len(np.array(image).shape) == 3:\n",
        "      image = tf.image.rgb_to_grayscale(image)\n",
        "    image_tensor = tf.convert_to_tensor(image)\n",
        "    image_tensor = tf.cast(image_tensor, tf.float32)\n",
        "    image_tensor = tf.expand_dims(image_tensor, 0)\n",
        "    image_tensor = image_tensor / 255.0\n",
        "    prediction = model.predict(image_tensor)\n",
        "    prediction_label = str(prediction.argmax())\n",
        "\n",
        "    return prediction_label\n",
        "\n",
        "title = \"Draw to Search\"\n",
        "description = \"Using the power of AI to detect the number you draw!\"\n",
        "article = \"for source code you can visit [my github](https://github.com/mralamdari)\"\n",
        "\n",
        "example_list = [[\"examples/\" + example] for example in os.listdir(\"examples\")]\n",
        "\n",
        "interface = gr.Interface(fn=classify_image,\n",
        "                          inputs=gr.Image(type=\"pil\"),\n",
        "                          outputs=gr.Label(num_top_classes=3, label=\"Predictions\"),\n",
        "                          examples=example_list,\n",
        "                          title=title,\n",
        "                          description=description,\n",
        "                          article=article)\n",
        "\n",
        "interface.launch()"
      ],
      "metadata": {
        "id": "__gYiDP0kSXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classify_image()"
      ],
      "metadata": {
        "id": "fDu4ZW4jf7he"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = np.zeros(shape=(28, 28))\n",
        "for i in range(img.shape[0]):\n",
        "  for j in range(img.shape[0]):\n",
        "    if np.random.rand()<0.5:\n",
        "      img[i][j] = 1"
      ],
      "metadata": {
        "id": "hT1kBVBfrBTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classify_image(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oEzEGCKWrbTF",
        "outputId": "b079f2fb-6e95-41d9-c96c-3713dfa8a8ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 372ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zZ0wNJKFrkgy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}