{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPxOm3tKehVyh59M7STvqtp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/Machine_Learning_Projects/blob/main/Digit_Classifier_with_Mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Approch"
      ],
      "metadata": {
        "id": "aT6lU7DJtI3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "fuVqcy2Bte3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = sklearn.datasets.fetch_openml('mnist_784', version=1)"
      ],
      "metadata": {
        "id": "cRuyVBKXt29C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = mnist.data, mnist.target"
      ],
      "metadata": {
        "id": "_INmrPift9d5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "_6D8ItxquDJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(X, Y, random_state=77, test_size=0.2)"
      ],
      "metadata": {
        "id": "HRWASH0Pt9VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardization(x):\n",
        "    return (x - np.mean(x, axis=0)) / np.std(x, axis=0)\n",
        "\n",
        "x_train_temp = standardization(x_train)\n",
        "x_test_temp = standardization(x_test)\n",
        "x_train_std, x_test_std = np.nan_to_num(x_train_temp), np.nan_to_num(x_test_temp)\n",
        "\n",
        "\n",
        "clf = sklearn.ensemble.RandomForestClassifier()\n",
        "clf.fit(x_train, y_train)\n",
        "sgd_pred = clf.predict(x_test)\n",
        "sklearn.metrics.accuracy_score(y_test, sgd_pred)"
      ],
      "metadata": {
        "id": "l4KJtymGtIV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Approch"
      ],
      "metadata": {
        "id": "abVHHzpHtesA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNOtI50P0i7X"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size=784     # images 784*784\n",
        "out_size=10        # 10 numbers\n",
        "epochs=10          # Iterations   \n",
        "batch_size=100     \n",
        "learning_rate=0.001 "
      ],
      "metadata": {
        "id": "I6KmilZrFCH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_gray = 0.1307\n",
        "std_grey  = 0.3081\n",
        "\n",
        "transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
        "                                             torchvision.transforms.Normalize((mean_gray, ), (std_grey, ))])"
      ],
      "metadata": {
        "id": "tVhYCS6GGJfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = torchvision.datasets.MNIST(root='/data',\n",
        "                                      train = True,\n",
        "                                      transform = torchvision.transforms.ToTensor(),\n",
        "                                      download=True)"
      ],
      "metadata": {
        "id": "JDFdMsCA0q4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = torchvision.datasets.MNIST(root='/data',\n",
        "                                      train=False,\n",
        "                                      transform = torchvision.transforms.ToTensor(),\n",
        "                                      download=True)"
      ],
      "metadata": {
        "id": "OsEJZjOmrzy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_ds,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)"
      ],
      "metadata": {
        "id": "33nOBQVA1sn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = torch.utils.data.DataLoader(test_ds, \n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "id": "whcDf75UsKPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
        "    self.batchnorm1 = torch.nn.BatchNorm2d(8)\n",
        "    self.relu = torch.nn.ReLU()\n",
        "    self.maxpool = torch.nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv2 = torch.nn.Conv2d(in_channels=8, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
        "    self.batchnorm2 = torch.nn.BatchNorm2d(32)\n",
        "    self.fc1 = torch.nn.Linear(32*7*7, 600)\n",
        "    self.dropout = torch.nn.Dropout(p=0.5)\n",
        "    self.fc2 = torch.nn.Linear(600, 100)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv1(x)\n",
        "    out = self.batchnorm1(out)\n",
        "    out = self.relu(out)  \n",
        "    out = self.maxpool(out)\n",
        "    out = self.conv2(out)\n",
        "    out = self.batchnorm2(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.maxpool(out)\n",
        "\n",
        "    out = out.view(-1, 1568)\n",
        "\n",
        "    out = self.fc1(out)\n",
        "    out = self.dropout(out)\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "4Im3OMgl22V7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(device)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "_lfqPRpEJ-G3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=20\n",
        "train_loss = []\n",
        "train_accuracy = []\n",
        "test_loss = []\n",
        "test_accuracy = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  correct = 0\n",
        "  iterations = 0\n",
        "  iter_loss = 0.0\n",
        "\n",
        "  model.train()\n",
        "  for i, (inputs, labels) in enumerate(train_loader):\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "    iter_loss += loss.item()\n",
        "    optimizer.zero_grad() \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    _, pred = torch.max(outputs, 1)\n",
        "    correct += (pred == labels).sum().item()\n",
        "    iterations += 1\n",
        "  \n",
        "  train_loss.append(iter_loss/iterations)\n",
        "  train_accuracy.append(100 * correct/ len(train_ds))\n",
        "  \n",
        "  t_loss = 0.0\n",
        "  correct = 0\n",
        "  iterations = 0\n",
        "  model.eval()\n",
        "  for i, (inputs, labels) in enumerate(test_loader):\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "    t_loss += loss.item()\n",
        "    _, pred = torch.max(outputs, 1) #(100, 10)  ==> 10 is in index 1\n",
        "    correct += (pred == labels).sum().item()\n",
        "    iterations += 1\n",
        "\n",
        "    test_loss.append(t_loss/iterations)\n",
        "    test_accuracy.append(100*correct/len(test_ds))\n",
        "\n",
        "\n",
        "  print(f'epoch: {epoch}, Training Loss: {train_loss[-1]:.3f}, Training Accuracy: %{train_accuracy[-1]:.3f}, Test Loss: {test_loss[-1]:.3f}, Test Accuracy:% {test_accuracy[-1]:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z1hn8IMPqfB",
        "outputId": "745bf7c5-1342-4b23-a87f-dc14036110d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, Training Loss: 0.119, Training Accuracy: %97.508, Test Loss: 0.131, Test Accuracy:% 97.760\n",
            "epoch: 1, Training Loss: 0.110, Training Accuracy: %97.672, Test Loss: 0.106, Test Accuracy:% 97.330\n",
            "epoch: 2, Training Loss: 0.109, Training Accuracy: %97.673, Test Loss: 0.086, Test Accuracy:% 98.390\n",
            "epoch: 3, Training Loss: 0.115, Training Accuracy: %97.658, Test Loss: 0.145, Test Accuracy:% 97.490\n",
            "epoch: 4, Training Loss: 0.121, Training Accuracy: %97.523, Test Loss: 0.110, Test Accuracy:% 97.910\n",
            "epoch: 5, Training Loss: 0.102, Training Accuracy: %97.762, Test Loss: 0.114, Test Accuracy:% 97.890\n",
            "epoch: 6, Training Loss: 0.112, Training Accuracy: %97.652, Test Loss: 0.096, Test Accuracy:% 97.720\n",
            "epoch: 7, Training Loss: 0.115, Training Accuracy: %97.557, Test Loss: 0.095, Test Accuracy:% 97.620\n",
            "epoch: 8, Training Loss: 0.121, Training Accuracy: %97.507, Test Loss: 0.109, Test Accuracy:% 98.030\n",
            "epoch: 9, Training Loss: 0.117, Training Accuracy: %97.625, Test Loss: 0.144, Test Accuracy:% 97.870\n",
            "epoch: 10, Training Loss: 0.107, Training Accuracy: %97.747, Test Loss: 0.125, Test Accuracy:% 97.770\n",
            "epoch: 11, Training Loss: 0.135, Training Accuracy: %97.302, Test Loss: 0.117, Test Accuracy:% 97.370\n",
            "epoch: 12, Training Loss: 0.123, Training Accuracy: %97.372, Test Loss: 0.109, Test Accuracy:% 97.580\n",
            "epoch: 13, Training Loss: 0.103, Training Accuracy: %97.597, Test Loss: 0.100, Test Accuracy:% 98.070\n",
            "epoch: 14, Training Loss: 0.108, Training Accuracy: %97.537, Test Loss: 0.096, Test Accuracy:% 98.280\n",
            "epoch: 15, Training Loss: 0.103, Training Accuracy: %97.563, Test Loss: 0.112, Test Accuracy:% 97.850\n",
            "epoch: 16, Training Loss: 0.109, Training Accuracy: %97.575, Test Loss: 0.100, Test Accuracy:% 97.960\n",
            "epoch: 17, Training Loss: 0.122, Training Accuracy: %97.410, Test Loss: 0.099, Test Accuracy:% 98.510\n",
            "epoch: 18, Training Loss: 0.121, Training Accuracy: %97.428, Test Loss: 0.101, Test Accuracy:% 98.060\n",
            "epoch: 19, Training Loss: 0.105, Training Accuracy: %97.663, Test Loss: 0.096, Test Accuracy:% 97.740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(6, 6, figsize = (20, 20))\n",
        "plt.gray()\n",
        "\n",
        "# loop through subplots and add centroid images\n",
        "for i, ax in enumerate(axs.flat):\n",
        "    \n",
        "    # determine inferred label using cluster_labels dictionary\n",
        "    for key, value in cluster_labels.items():\n",
        "        if i in value:\n",
        "            ax.set_title('Inferred Label: {}'.format(key))\n",
        "    \n",
        "    # add image to subplot\n",
        "    ax.matshow(images[i])\n",
        "    ax.axis('off')\n",
        "    \n",
        "# display the figure\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "hGvjQzu0ol7N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}